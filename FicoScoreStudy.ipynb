{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation / Motivation:\n",
    "- Study on non-discriminatory supervised learning models\n",
    "- This data set is a case study on FICO scores and how they determine a 'threshold' cutoff score to either deny or approve a loan application\n",
    "- Using data from the Federal Reserve, we can see the distribution of scores (FICO score percentile) against four main demographic groups: Asian, Hispanic, Black, and White\n",
    "- With this data, we can plot the probability of defaulting and/or non-defaulting people from a specified demographpic group getting approved a loan ($\\hat Y$ = 1).\n",
    "- Theoretically, the probability of defaulting and/or non-defaulting people getting ($\\hat Y$ = 1) should be equal amongst all demographic groups, but as you can see from this study, that is not the case.\n",
    "- I dive into what this means in terms of precision/recall, the cost of these discrepencies, why this is happening, as well as methodologies for improvement.\n",
    "- Data and non-descriminitaory model analysis courtesy of https://arxiv.org/pdf/1610.02413.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import fileinput\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.lines as mlines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Data from Federal Reserve:\n",
    "#### Explanations / Guidelines:\n",
    "- All files are saved in current directory\n",
    "- We will be analyzing \"Figure_7.D._TransRisk_Score_Cumulative_Percentage_of_Goods_and_Bads,_by_Demographic_Group(Random-Account_Performance)_-_Race_or_ethnicity_(SSA_data).csv\" and saving that file as 'random-account-ficoscores.csv' for easier reference\n",
    "- To analyze the Cumulative Percentage of Goods and Bads for any of the other protected groups (sex, age, marital status, or income ratio) simply plug in this csv when assigning the 'data' variable\n",
    "- Options for account types: any-account, new-account, existing-account, random-account\n",
    "- In this study, \"good\" means non-defaulting for loans (will pay it off). \"Bad\" means defaulting for loans (will not pay it off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# url = \"www.federalreserve.gov/boarddocs/rptcongress/creditscore/overviewfigtables.htm\"\n",
    "# r  = requests.get(\"https://\" +url)\n",
    "# data = r.text\n",
    "# soup = BeautifulSoup(data, 'lxml')\n",
    "\n",
    "\n",
    "# def cell_text(cell):\n",
    "#     return \" \".join(cell.stripped_strings)\n",
    "\n",
    "# for table in soup.find_all('table'):\n",
    "#     title = table.find('span', { 'class' : 'tablehead' }).getText()\n",
    "#     subhead = table.find('span', { 'class' : 'tablesubheadsmall' }).getText()\n",
    "#     fname = (title + ' - '+subhead).replace(' ', '_') + '.csv'\n",
    "#     fname = fname.replace(':', '-')\n",
    "#     with open(fname, 'w') as outfile:\n",
    "#         output = csv.writer(outfile)\n",
    "\n",
    "#         for row in table.find_all('tr'):\n",
    "#             col = map(cell_text, row.find_all(re.compile('t[dh]')))\n",
    "#             output.writerow(col)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.rename('Figure_7.D._TransRisk_Score-_Cumulative_Percentage_of_Goods_and_Bads,_by_Demographic_Group(Random-Account_Performance)_-_Race_or_ethnicity_(SSA_data).csv', 'random-account-ficoscores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** HERE IS WHERE I CALCULATE THE CONDENSED VERSION OF THE DATA! ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPD(goodName, badName, data, raceName):\n",
    "    pd = data['Score'].to_frame(name=\"Score\")\n",
    "    race = np.full(len(data[badName]), raceName)\n",
    "    pd[\"Demographic\"] = race\n",
    "    pd[\"Good\"] = data[goodName].copy()\n",
    "    pd[\"Bad\"] = data[badName].copy()\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ficoscores.csv\")\n",
    "#Necessary to rename this column for clarity of the data it represents\n",
    "#because of formatting issues when parsing data from the html\n",
    "data.rename(columns={'Black (Bad).1':'Hispanic (Good)'}, inplace=True)\n",
    "data.rename(columns={'Non- Hispanic white (Good)':'White (Good)'}, inplace=True)\n",
    "data.rename(columns={'Non- Hispanic white (Bad)': 'White (Bad)'}, inplace=True)\n",
    "whites = getPD('White (Good)', 'White (Bad)', data, \"white\")\n",
    "blacks = getPD('Black (Good)', 'Black (Bad)', data, \"black\")\n",
    "asians = getPD('Asian (Good)', 'Asian (Bad)', data, \"asian\")\n",
    "hispanics = getPD('Hispanic (Good)', 'Hispanic (Bad)', data, \"hispanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSeries(data, goodOrBad):\n",
    "    one = data[data[\"Score\"] <= 20.0][goodOrBad].mean()\n",
    "    two = data[data[\"Score\"] > 20.0][data[\"Score\"] <= 40.0][goodOrBad].mean()\n",
    "    three = data[data[\"Score\"] > 40.0][data[\"Score\"] <= 60.0][goodOrBad].mean()\n",
    "    four = data[data[\"Score\"] > 60.0][data[\"Score\"] <= 80.0][goodOrBad].mean()\n",
    "    five = data[data[\"Score\"] > 80.0][data[\"Score\"] <= 100.0][goodOrBad].mean()\n",
    "    return pd.Series([one, two, three, four, five])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scores = pd.Series([20, 40, 60, 80, 100])\n",
    "whitef = pd.DataFrame({ 'Score' : scores,\n",
    "    'Demographic' : np.full(len(scores), \"white\"),\n",
    "    'Good' : getSeries(whites, \"Good\"),\n",
    "    'Bad' : getSeries(whites, \"Bad\") })\n",
    "asianf = pd.DataFrame({ 'Score' : scores,\n",
    "    'Demographic' : np.full(len(scores), \"asian\"),\n",
    "    'Good' : getSeries(asians, \"Good\"),\n",
    "    'Bad' : getSeries(asians, \"Bad\") })\n",
    "blackf = pd.DataFrame({ 'Score' : scores,\n",
    "    'Demographic' : np.full(len(scores), \"black\"),\n",
    "    'Good' : getSeries(blacks, \"Good\"),\n",
    "    'Bad' : getSeries(blacks, \"Bad\") })\n",
    "hispanicf = pd.DataFrame({ 'Score' : scores,\n",
    "    'Demographic' : np.full(len(scores), \"hispanic\"),\n",
    "    'Good' : getSeries(hispanics, \"Good\"),\n",
    "    'Bad' : getSeries(hispanics, \"Bad\") })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [whitef, blackf, asianf, hispanicf]\n",
    "shortenedData = pd.concat(frames)\n",
    "shortenedData.rename(columns={'Score' : 'TransRisk Score'}, inplace=True)\n",
    "shortenedData = shortenedData[[\"TransRisk Score\", \"Demographic\", \"Good\", \"Bad\"]]\n",
    "shortenedData.set_index(\"TransRisk Score\", inplace=True)\n",
    "shortenedData.to_csv(\"ShortenedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demographic</th>\n",
       "      <th>Good</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransRisk Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>white</td>\n",
       "      <td>2.937317</td>\n",
       "      <td>33.903415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>white</td>\n",
       "      <td>16.767500</td>\n",
       "      <td>75.331500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>white</td>\n",
       "      <td>42.716500</td>\n",
       "      <td>93.436250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>white</td>\n",
       "      <td>68.186316</td>\n",
       "      <td>98.261842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>white</td>\n",
       "      <td>91.210769</td>\n",
       "      <td>99.636667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>black</td>\n",
       "      <td>7.099756</td>\n",
       "      <td>40.861463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>black</td>\n",
       "      <td>30.374000</td>\n",
       "      <td>82.746250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>black</td>\n",
       "      <td>59.725250</td>\n",
       "      <td>96.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>black</td>\n",
       "      <td>80.675000</td>\n",
       "      <td>99.160263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>black</td>\n",
       "      <td>95.074872</td>\n",
       "      <td>99.818974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>asian</td>\n",
       "      <td>2.433659</td>\n",
       "      <td>32.685122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>asian</td>\n",
       "      <td>15.684000</td>\n",
       "      <td>72.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>asian</td>\n",
       "      <td>43.089000</td>\n",
       "      <td>93.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>asian</td>\n",
       "      <td>69.935000</td>\n",
       "      <td>98.564474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>asian</td>\n",
       "      <td>91.696410</td>\n",
       "      <td>99.771795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>4.605122</td>\n",
       "      <td>36.472927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>24.646500</td>\n",
       "      <td>78.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>55.591250</td>\n",
       "      <td>94.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>78.807105</td>\n",
       "      <td>98.983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>94.638205</td>\n",
       "      <td>99.884615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Demographic       Good        Bad\n",
       "TransRisk Score                                  \n",
       "20                    white   2.937317  33.903415\n",
       "40                    white  16.767500  75.331500\n",
       "60                    white  42.716500  93.436250\n",
       "80                    white  68.186316  98.261842\n",
       "100                   white  91.210769  99.636667\n",
       "20                    black   7.099756  40.861463\n",
       "40                    black  30.374000  82.746250\n",
       "60                    black  59.725250  96.141000\n",
       "80                    black  80.675000  99.160263\n",
       "100                   black  95.074872  99.818974\n",
       "20                    asian   2.433659  32.685122\n",
       "40                    asian  15.684000  72.759500\n",
       "60                    asian  43.089000  93.847500\n",
       "80                    asian  69.935000  98.564474\n",
       "100                   asian  91.696410  99.771795\n",
       "20                 hispanic   4.605122  36.472927\n",
       "40                 hispanic  24.646500  78.119500\n",
       "60                 hispanic  55.591250  94.674000\n",
       "80                 hispanic  78.807105  98.983421\n",
       "100                hispanic  94.638205  99.884615"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortenedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** END OF CONDENSED DATA CALCULATION ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Total Data Calculation ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPD(goodName, badName, data, raceName):\n",
    "    pd = data['Score'].to_frame(name=\"Score\")\n",
    "    race = np.full(len(data), raceName)\n",
    "    pd[\"Demographic\"] = race\n",
    "    pd[\"Good\"] = data[goodName].copy()\n",
    "    pd[\"Bad\"] = data[badName].copy()\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ficoscores.csv\")\n",
    "#Necessary to rename this column for clarity of the data it represents\n",
    "#because of formatting issues when parsing data from the html\n",
    "data.rename(columns={'Black (Bad).1':'Hispanic (Good)'}, inplace=True)\n",
    "data.rename(columns={'Non- Hispanic white (Good)':'White (Good)'}, inplace=True)\n",
    "data.rename(columns={'Non- Hispanic white (Bad)': 'White (Bad)'}, inplace=True)\n",
    "whites = getPD('White (Good)', 'White (Bad)', data, \"white\")\n",
    "blacks = getPD('Black (Good)', 'Black (Bad)', data, \"black\")\n",
    "asians = getPD('Asian (Good)', 'Asian (Bad)', data, \"asian\")\n",
    "hispanics = getPD('Hispanic (Good)', 'Hispanic (Bad)', data, \"hispanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demographic</th>\n",
       "      <th>Good</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransRisk Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>white</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>white</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>white</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>white</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>white</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Demographic  Good    Bad\n",
       "TransRisk Score                         \n",
       "0.0                   white  0.00   0.17\n",
       "0.5                   white  0.03   1.85\n",
       "1.0                   white  0.22   7.26\n",
       "1.5                   white  0.26   8.85\n",
       "2.0                   white  0.35  10.58"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [whites, blacks, asians, hispanics]\n",
    "totalData = pd.concat(frames)\n",
    "totalData.rename(columns={'Score' : 'TransRisk Score'}, inplace=True)\n",
    "totalData.set_index(\"TransRisk Score\", inplace=True)\n",
    "totalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalData.to_csv(\"TransRiskScores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Workspace for solution and Tutorial below! ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Non- Hispanic white (Good)'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2f3cbd0b2274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwhite_non_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Non- Hispanic white (Good)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwhite_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Non- Hispanic white (Bad)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mblack_non_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Black (Good)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mblack_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Black (Bad)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhispanic_non_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Hispanic (Good)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Non- Hispanic white (Good)'] not in index\""
     ]
    }
   ],
   "source": [
    "white_non_default = data[[\"Score\", \"Non- Hispanic white (Good)\"]]\n",
    "white_default = data[[\"Score\",\"Non- Hispanic white (Bad)\"]]\n",
    "black_non_default = data[[\"Score\",\"Black (Good)\"]]\n",
    "black_default = data[[\"Score\",\"Black (Bad)\"]]\n",
    "hispanic_non_default = data[[\"Score\",\"Hispanic (Good)\"]]\n",
    "hispanic_default = data[[\"Score\",\"Hispanic (Bad)\"]]\n",
    "asian_non_default = data[[\"Score\",\"Asian (Good)\"]]\n",
    "asian_default = data[[\"Score\",\"Asian (Bad)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getGraph(dataset, metricName, graphType):\n",
    "    i= 0\n",
    "    x = []\n",
    "    y = []\n",
    "    while(i < 100.5):\n",
    "        if(i == 72.5 or i == 77.5 or i == 92.5):\n",
    "            i = (i + 0.5)\n",
    "        curr_race_non_default = dataset[dataset[\"Score\"] >= i][metricName].sum()\n",
    "        total_race_non_default = dataset[metricName].sum()\n",
    "        yVal = curr_race_non_default / total_race_non_default\n",
    "        x.append(i)\n",
    "        y.append(yVal)\n",
    "        i = (i + 0.5)\n",
    "    plt.plot(x, y, graphType, label=metricName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing This Data:\n",
    "#### Now we have data for how many people are defaulters and non-defaulters for each score, theoretically the probability of a non-defaulter getting approved a loan ($\\hat Y$ = 1) should be the same amongst all four groups. You can see from the graph that this is not the case: a person from the black demographic group is much less likely to be approved than a white or asian non-defaulting person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getGraph(asian_non_default, \"Asian (Good)\", 'b-')\n",
    "getGraph(white_non_default, \"Non- Hispanic white (Good)\", 'g-')\n",
    "getGraph(black_non_default, \"Black (Good)\", 'c-')\n",
    "getGraph(hispanic_non_default, \"Hispanic (Good)\", 'm-')\n",
    "plt.title(\"Probability of Non-Defaulters Getting $\\hat Y$ = 1 (Beneficial Outcome)\" )\n",
    "\n",
    "\n",
    "blue_line = mlines.Line2D([], [], color='blue', marker='.',\n",
    "                          markersize=15, label='Asian')\n",
    "green_line = mlines.Line2D([], [], color='green', marker='.',\n",
    "                          markersize=15, label='White')\n",
    "cyan_line = mlines.Line2D([], [], color='cyan', marker='.',\n",
    "                          markersize=15, label='Black')\n",
    "purple_line = mlines.Line2D([], [], color='purple', marker='.',\n",
    "                          markersize=15, label='Hispanic')\n",
    "\n",
    "plt.legend(handles=[blue_line, green_line, cyan_line, purple_line])\n",
    "\n",
    "#todo: compare the defaulters getting beneficial outcome too\n",
    "#facetgrid and seaborn - make variable 'default' or 'non-default' or 'race' for 1 panel for each race\n",
    "# recall - x\n",
    "# precision - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asian_non_default.to_csv(\"asian-non-default.csv\")\n",
    "asian_default.to_csv(\"asian-default.csv\")\n",
    "white_non_default.to_csv(\"white-non-default.csv\")\n",
    "white_default.to_csv(\"white-default.csv\")\n",
    "black_non_default.to_csv(\"black-non-default.csv\")\n",
    "black_default.to_csv(\"black-default.csv\")\n",
    "hispanic_non_default.to_csv(\"hispanic-non-default.csv\")\n",
    "hispanic_default.to_csv(\"hispanic-default.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(asian_non_default.to_csv, open(\"asian-non-default.pkl\", \"wb\"))\n",
    "pickle.dump(asian_default, open(\"asian-default.pkl\", \"wb\"))\n",
    "pickle.dump(white_non_default, open(\"white-non-default.pkl\", \"wb\"))\n",
    "pickle.dump(white_default, open(\"white-default.pkl\", \"wb\"))\n",
    "pickle.dump(black_non_default, open(\"black-non-default.pkl\", \"wb\"))\n",
    "pickle.dump(black_default, open(\"black-default.pkl\", \"wb\"))\n",
    "pickle.dump(hispanic_non_default, open(\"hispanic-non-default.pkl\", \"wb\"))\n",
    "pickle.dump(hispanic_default, open(\"hispanic-default.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision / Recall Analysis\n",
    "\n",
    "##### Recall: Of all non-defaulters, how many did we correctly identify as non-defaulters (Gave beneficial outcome?)\n",
    "- true positives / (total false negatives and true positives)\n",
    "- correctly predicted non-defaulters / all non-defaulters\n",
    "\n",
    "##### Precision: Of the non-defaulters we predicted (given a beneficial outcome?), how many were actually non-defaulting\n",
    "- true positives / true positives + false positives\n",
    "- correctly identified non-defaulters / all predicted non-defaulters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "- true: non-defaulting (they are a good candidate for a loan)\n",
    "- good precision: good precision would mean out of the people that we predict are going to pay it, a high percentage actually are\n",
    "- poor precision: out of the people that we predict are going to pay it, a low percentage actually will\n",
    "\n",
    "*** This is why banks are looking for good precision for lower risk / cost on their part, but the non-discriminatory models attempt to put the burden of this cost on the data scientist to make more accurate models and away from the minority/protected group\n",
    "\n",
    "- recall: of the people who would pay it back, how many did we correctly identify\n",
    "- F-1 scores, can weight precision or recall depending on what is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Analysis / Problem Space\n",
    "- Cost that accompanies low precision\n",
    "- What kinds of companies might risk placing cost on discriminated-against groups (even by accident)\n",
    "- What data sets and attributes are most commonly 'protected' and what kinds of models need to be re-trained to fit ethical platforms\n",
    "- How non-discriminatory supervised learning models can come into play on already-trained data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Solutions\n",
    "(Non-Discriminatory Supervised Learning Models)\n",
    "- Explanation of non-discriminatory supervised learning models\n",
    "- Max Profit Classifier, Race Blind Classifier, Demographic Parity Classifier, Equal Opportunity Classifier, Equal Odds Classifier\n",
    "- Pros/Cons of using each one\n",
    "- Examples of when one might be better over another\n",
    "- Recommendations for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
